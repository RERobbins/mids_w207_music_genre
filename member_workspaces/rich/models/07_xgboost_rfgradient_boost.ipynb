{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b223e5e3-01fe-4df3-8c86-f8801c3506c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "\n",
    "from helpers.split import tag_label_feature_split, make_train_test_split\n",
    "from helpers.assess import make_confusion_matrix, make_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f6ff4-3f9c-4a4d-b16a-ea71a4398d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfcross_gradient_boost_experiment(dataset):\n",
    "\n",
    "    # load data and separate one hot encoded labels from features,\n",
    "    # transform one hot encoded labels into label strings,\n",
    "    # then encode label strings\n",
    "\n",
    "    print(f\"\\n\\nDataset: {dataset}\\n\")\n",
    "\n",
    "    df = pd.read_pickle(dataset)\n",
    "    _, (y, le) , X = tag_label_feature_split(df,label_format='encoded')\n",
    "\n",
    "    # divide into train and test data sets\n",
    "    X_train_std, X_test_std, y_train, y_test = make_train_test_split(\n",
    "        X, y, test_size=0.2, random_state=10, stratify=y,x_scaler=\"standard\"\n",
    "    )\n",
    "\n",
    "    # calculate sample weights to deal with class imbalance\n",
    "\n",
    "    sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "    model = XGBRFClassifier(\n",
    "        use_label_encoder=False, objective=\"multi:softprob\", eval_metric=\"mlogloss\",\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_std, y_train, sample_weight=sample_weights)\n",
    "\n",
    "    predictions = model.predict(X_test_std)\n",
    "    train_accuracy = model.score(X_train_std, y_train)\n",
    "    test_accuracy = model.score(X_test_std, y_test)\n",
    "\n",
    "    print(f\"Train: {train_accuracy = :f}\\n\")\n",
    "    make_classification_report(y_train,model=model,x=X_train_std,label_encoder=le,print_report=True)\n",
    "    print(f\"Test: {test_accuracy = :f}\\n\")\n",
    "    make_classification_report(y_test, y_pred=predictions, digits=4,label_encoder=le,print_report=True)\n",
    "    \n",
    "    name = os.path.basename(dataset).split(\".\")[0]\n",
    "    make_confusion_matrix(\n",
    "        y_test,\n",
    "        y_pred=predictions,\n",
    "        label_encoder=le,\n",
    "        title=f\"{name} test (row normalized)\"\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd26f2-dc67-4974-bdf4-34678317bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"../../../datasets/\"\n",
    "datasets = sorted([name for name in glob.glob(dataset_folder + \"*.pickle\")])\n",
    "for dataset in datasets:\n",
    "    rfcross_gradient_boost_experiment(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
