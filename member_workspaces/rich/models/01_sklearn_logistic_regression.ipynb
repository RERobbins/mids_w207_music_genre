{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b223e5e3-01fe-4df3-8c86-f8801c3506c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzywuzzy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression, LogisticRegressionCV\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_classification_report, make_confusion_matrix\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msplit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_train_test_split, tag_label_feature_split\n",
      "File \u001b[0;32m~/github/mids-w207/mids_w207_music_genre/member_workspaces/rich/models/../../../helpers/assess.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, matthews_corrcoef\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_sample_weight\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m results\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_confusion_matrix\u001b[39m(\n\u001b[1;32m     10\u001b[0m   y_true,\n\u001b[1;32m     11\u001b[0m   y_pred\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# optionally pass in precalculated y predictions\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m   \u001b[38;5;66;03m# resolve polymorphisms / optional values\u001b[39;00m\n\u001b[1;32m     25\u001b[0m   y_pred \u001b[38;5;241m=\u001b[39m resolve_y_pred(\n\u001b[1;32m     26\u001b[0m     y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     28\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m     29\u001b[0m   )\n",
      "File \u001b[0;32m~/github/mids-w207/mids_w207_music_genre/member_workspaces/rich/models/../../../helpers/save.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuzz\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# make sure you installed fuzzywuzzy and python-Levenshtein\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzywuzzy'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from helpers.assess import make_classification_report, make_confusion_matrix\n",
    "from helpers.split import make_train_test_split, tag_label_feature_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f6ff4-3f9c-4a4d-b16a-ea71a4398d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_experiment(\n",
    "    dataset, optimizer=\"lbfgs\", max_iteration=1000, verbose=0\n",
    "):\n",
    "\n",
    "    # load data and separate label strings from features,\n",
    "    # then encode label strings\n",
    "\n",
    "    print(f\"\\n\\nDataset: {dataset}\\n\")\n",
    "\n",
    "    df = pd.read_pickle(dataset)\n",
    "    _, (y, le), X = tag_label_feature_split(df, label_format=\"encoded\")\n",
    "\n",
    "    # divide into train and test data sets\n",
    "    X_train_std, X_test_std, y_train, y_test = make_train_test_split(\n",
    "        X, y, test_size=0.2, random_state=10, stratify=y, x_scaler=\"standard\"\n",
    "    )\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=100.0,\n",
    "        solver=optimizer,\n",
    "        multi_class=\"multinomial\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=max_iteration,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_std, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test_std)\n",
    "    train_accuracy = model.score(X_train_std, y_train)\n",
    "    test_accuracy = model.score(X_test_std, y_test)\n",
    "\n",
    "    print(f\"Train: {train_accuracy = :f}\\n\")\n",
    "    make_classification_report(\n",
    "        y_train,\n",
    "        model=model,\n",
    "        x=X_train_std,\n",
    "        digits=4,\n",
    "        label_encoder=le,\n",
    "        print_report=True,\n",
    "    )\n",
    "    print(f\"Test: {test_accuracy = :f}\\n\")\n",
    "    make_classification_report(\n",
    "        y_test, y_pred=predictions, digits=4, label_encoder=le, print_report=True\n",
    "    )\n",
    "\n",
    "    name = os.path.basename(dataset).split(\".\")[0]\n",
    "    make_confusion_matrix(\n",
    "        y_test,\n",
    "        y_pred=predictions,\n",
    "        label_encoder=le,\n",
    "        title=f\"{name} test (row normalized)\",\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67320a4-fd88-4b6e-9249-02dd0c79ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"../../../datasets/\"\n",
    "datasets = sorted([name for name in glob.glob(dataset_folder + \"dataset_*.pickle\")])\n",
    "for dataset in datasets:\n",
    "    logistic_regression_experiment(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f7f94-5703-44f8-b864-ee1ec2df57b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../../datasets/dataset_00_all.pickle_skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945ac57-28eb-42a4-8a2e-1032ef154966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf90570-060c-43b5-987c-c82848e757c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ebde3-852f-4351-8913-4aca1c050068",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24bf0e7-f813-483d-a939-8616acda932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c87c6-3398-447b-98f1-7a1ae9bb48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129032c7-7997-422f-a14d-181e78dde025",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric=df.select_dtypes(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058e856-e5f9-46a7-8105-acb7607d7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a201a5c-0277-4d9f-a22c-5e1c4fc98137",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611cd40-a9e7-45ce-aba1-2de96e45e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f4409-774b-4e8a-969c-62ea8a9d3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797416a4-20ea-44aa-8dbe-549f3cb6506b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
